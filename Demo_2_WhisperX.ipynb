{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhuarancca/fullstack-course1-module2/blob/master/Demo_2_WhisperX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eb38cc7",
      "metadata": {
        "id": "3eb38cc7"
      },
      "source": [
        "# **WhisperX Demo** 🎙️✨\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bce6f74",
      "metadata": {
        "id": "1bce6f74"
      },
      "source": [
        "Jugando con WhisperX, la increíble herramienta de transcripción de voz. Si tienes un archivo de audio y quieres convertirlo en texto, sigue las instrucciones a continuación y verás lo fácil que es.\n",
        "\n",
        "## ¿Cómo empezar? 🚀\n",
        "\n",
        "1. **Habilita la GPU**: Para obtener una transcripción rápida, asegúrate de habilitar la GPU. Ve a \"Runtime\" > \"Change runtime type\" > y selecciona \"GPU\" en la opción \"Hardware accelerator\".\n",
        "2. **Sube tu archivo de audio**: Usa la herramienta de abajo para subir tu archivo de audio.\n",
        "3. **Ejecuta las celdas**: Simplemente ejecuta las celdas en orden, ¡y verás la magia suceder!\n",
        "\n",
        "**Nota**: Si eres nuevo en Google Colab, cada celda con código se ejecuta haciendo clic en el botón de reproducción (▶️) a la izquierda de la celda, o puedes presionar `Shift + Enter`.\n",
        "\n",
        "## Instalación del paquete 📦\n",
        "\n",
        "Primero, necesitamos instalar WhisperX. Si ya lo tienes instalado, asegúrate de tener la versión más reciente. Puedes hacerlo ejecutando la celda de abajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "839c047c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "839c047c",
        "outputId": "4d05818a-d316-4ef0-c5ab-1e9c26976b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/m-bain/whisperx.git\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-_r8rrhi0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-_r8rrhi0\n",
            "  Resolved https://github.com/m-bain/whisperx.git to commit f2da2f858e99e4211fe4f64b5f2938b007827e17\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchaudio>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: faster-whisper==1.0.0 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (1.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (4.38.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.0.3)\n",
            "Requirement already satisfied: setuptools>=65 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (67.7.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.8.1)\n",
            "Requirement already satisfied: pyannote.audio==3.1.1 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.1.1)\n",
            "Requirement already satisfied: av==11.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (11.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (4.1.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.15.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (1.17.1)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.7.0)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.1)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.5.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (13.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n",
            "Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.1)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->whisperx==3.1.1) (12.4.127)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (0.4.2)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.9.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (3.20.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.11.4)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.7.1)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->whisperx==3.1.1) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.16.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.16.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.99)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->whisperx==3.1.1) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.10.1)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->whisperx==3.1.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (2024.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch>=2->whisperx==3.1.1) (3.9.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.1.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.29)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.4.0)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.5.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (10.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.18.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (4.2.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/m-bain/whisperx.git --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "568bde2d",
      "metadata": {
        "id": "568bde2d"
      },
      "source": [
        "## Sube tu archivo de audio 🎵\n",
        "\n",
        "Haz clic en el botón de abajo para subir tu archivo de audio. Asegúrate de que sea un archivo en formato MP3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0fdeeda0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "0fdeeda0",
        "outputId": "721bee37-66a6-444b-bf64-5f0e02c440f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1c0657a6-2e95-4d65-9f8e-dbdaa9f9a7ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1c0657a6-2e95-4d65-9f8e-dbdaa9f9a7ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Doksblog.com-Disturbed-The-Sound-Of-Silence-CYRIL-Remix-Official-Music.mp3 to Doksblog.com-Disturbed-The-Sound-Of-Silence-CYRIL-Remix-Official-Music.mp3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "audio_file = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f2303f",
      "metadata": {
        "id": "57f2303f"
      },
      "source": [
        "## Transcripción de voz 🗣️\n",
        "\n",
        "Ahora, vamos a transcribir tu archivo de audio. Puedes ajustar la `batch_size` y el `compute_type` según tus necesidades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "86825fe3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86825fe3",
        "outputId": "9e5b4e00-ff18-4241-a205-10de0abe3010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.2.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: en (0.77) in first 30s of audio...\n",
            "[{'text': \" And I'm darkness my own\", 'start': 6.186, 'end': 7.858}, {'text': ' In the sound of silence In restless dreams I walked alone Narrow streets of cobblestone Neath the halo of a street lamp I turned my collar to the cold and damp', 'start': 30.316, 'end': 49.309}, {'text': ' When my eyes will stand by the flash of a neon light That split the night and touch the sound of silence', 'start': 50.026, 'end': 64.343}, {'text': \" I'm silent. Fool said, are you?\", 'start': 89.292, 'end': 92.927}, {'text': ' Echoed in the wells of silence And the people bowed and prayed To the neon god they made And the sign flashed out in its warning And the words that it was forming', 'start': 114.36, 'end': 133.507}, {'text': ' In the signs and the words and the prophets are written on the subway walls and tenement halls and whispered in the sound of silence and in the naked light of', 'start': 134.684, 'end': 153.217}, {'text': ' Of silence', 'start': 177.807, 'end': 180.384}]\n",
            "[{'start': 6.246, 'end': 7.636, 'text': \" And I'm darkness my own\", 'words': [{'word': 'And', 'start': 6.246, 'end': 6.408, 'score': 0.426}, {'word': \"I'm\", 'start': 6.448, 'end': 6.649, 'score': 0.446}, {'word': 'darkness', 'start': 6.71, 'end': 7.153, 'score': 0.626}, {'word': 'my', 'start': 7.213, 'end': 7.375, 'score': 0.76}, {'word': 'own', 'start': 7.556, 'end': 7.636, 'score': 0.206}]}, {'start': 30.336, 'end': 48.869, 'text': ' In the sound of silence In restless dreams I walked alone Narrow streets of cobblestone Neath the halo of a street lamp I turned my collar to the cold and damp', 'words': [{'word': 'In', 'start': 30.336, 'end': 30.396, 'score': 0.25}, {'word': 'the', 'start': 30.556, 'end': 30.856, 'score': 0.667}, {'word': 'sound', 'start': 30.876, 'end': 31.317, 'score': 0.424}, {'word': 'of', 'start': 32.337, 'end': 32.397, 'score': 0.659}, {'word': 'silence', 'start': 32.457, 'end': 34.279, 'score': 0.529}, {'word': 'In', 'start': 34.739, 'end': 34.839, 'score': 0.612}, {'word': 'restless', 'start': 34.879, 'end': 35.259, 'score': 0.473}, {'word': 'dreams', 'start': 35.299, 'end': 35.56, 'score': 0.638}, {'word': 'I', 'start': 35.7, 'end': 35.72, 'score': 0.009}, {'word': 'walked', 'start': 35.86, 'end': 36.54, 'score': 0.227}, {'word': 'alone', 'start': 36.7, 'end': 37.681, 'score': 0.691}, {'word': 'Narrow', 'start': 38.722, 'end': 39.082, 'score': 0.944}, {'word': 'streets', 'start': 39.102, 'end': 39.402, 'score': 0.751}, {'word': 'of', 'start': 39.462, 'end': 39.562, 'score': 0.873}, {'word': 'cobblestone', 'start': 39.622, 'end': 41.584, 'score': 0.761}, {'word': 'Neath', 'start': 42.424, 'end': 42.644, 'score': 0.479}, {'word': 'the', 'start': 42.684, 'end': 42.845, 'score': 0.635}, {'word': 'halo', 'start': 42.905, 'end': 43.405, 'score': 0.772}, {'word': 'of', 'start': 43.505, 'end': 43.565, 'score': 0.162}, {'word': 'a', 'start': 43.805, 'end': 44.266, 'score': 0.818}, {'word': 'street', 'start': 44.286, 'end': 44.586, 'score': 0.736}, {'word': 'lamp', 'start': 44.606, 'end': 45.206, 'score': 0.65}, {'word': 'I', 'start': 46.107, 'end': 46.187, 'score': 0.514}, {'word': 'turned', 'start': 46.247, 'end': 46.467, 'score': 0.435}, {'word': 'my', 'start': 46.507, 'end': 46.667, 'score': 0.631}, {'word': 'collar', 'start': 46.707, 'end': 47.148, 'score': 0.701}, {'word': 'to', 'start': 47.208, 'end': 47.448, 'score': 0.845}, {'word': 'the', 'start': 47.468, 'end': 47.568, 'score': 0.199}, {'word': 'cold', 'start': 47.648, 'end': 48.188, 'score': 0.92}, {'word': 'and', 'start': 48.268, 'end': 48.388, 'score': 0.721}, {'word': 'damp', 'start': 48.408, 'end': 48.869, 'score': 0.376}]}, {'start': 50.026, 'end': 61.5, 'text': ' When my eyes will stand by the flash of a neon light That split the night and touch the sound of silence', 'words': [{'word': 'When', 'start': 50.026, 'end': 50.186, 'score': 0.908}, {'word': 'my', 'start': 50.286, 'end': 50.527, 'score': 0.885}, {'word': 'eyes', 'start': 50.727, 'end': 50.987, 'score': 0.513}, {'word': 'will', 'start': 51.007, 'end': 51.167, 'score': 0.361}, {'word': 'stand', 'start': 51.187, 'end': 51.868, 'score': 0.749}, {'word': 'by', 'start': 51.968, 'end': 52.309, 'score': 0.74}, {'word': 'the', 'start': 52.329, 'end': 52.389, 'score': 0.042}, {'word': 'flash', 'start': 52.429, 'end': 52.869, 'score': 0.663}, {'word': 'of', 'start': 53.01, 'end': 53.19, 'score': 0.565}, {'word': 'a', 'start': 53.25, 'end': 53.27, 'score': 0.035}, {'word': 'neon', 'start': 53.31, 'end': 54.031, 'score': 0.905}, {'word': 'light', 'start': 54.171, 'end': 54.772, 'score': 0.515}, {'word': 'That', 'start': 55.633, 'end': 55.753, 'score': 0.527}, {'word': 'split', 'start': 55.773, 'end': 56.594, 'score': 0.697}, {'word': 'the', 'start': 56.614, 'end': 56.794, 'score': 0.734}, {'word': 'night', 'start': 56.854, 'end': 57.815, 'score': 0.634}, {'word': 'and', 'start': 58.436, 'end': 58.536, 'score': 0.764}, {'word': 'touch', 'start': 58.576, 'end': 58.836, 'score': 0.875}, {'word': 'the', 'start': 58.856, 'end': 58.957, 'score': 0.968}, {'word': 'sound', 'start': 59.037, 'end': 59.858, 'score': 0.703}, {'word': 'of', 'start': 60.839, 'end': 60.899, 'score': 0.626}, {'word': 'silence', 'start': 60.959, 'end': 61.5, 'score': 0.555}]}, {'start': 89.392, 'end': 91.481, 'text': \" I'm silent.\", 'words': [{'word': \"I'm\", 'start': 89.392, 'end': 89.533, 'score': 0.298}, {'word': 'silent.', 'start': 89.553, 'end': 91.481, 'score': 0.76}]}, {'start': 91.923, 'end': 92.807, 'text': 'Fool said, are you?', 'words': [{'word': 'Fool', 'start': 91.923, 'end': 92.144, 'score': 0.774}, {'word': 'said,', 'start': 92.164, 'end': 92.345, 'score': 0.382}, {'word': 'are', 'start': 92.405, 'end': 92.485, 'score': 0.203}, {'word': 'you?', 'start': 92.686, 'end': 92.807, 'score': 0.346}]}, {'start': 114.38, 'end': 133.147, 'text': ' Echoed in the wells of silence And the people bowed and prayed To the neon god they made And the sign flashed out in its warning And the words that it was forming', 'words': [{'word': 'Echoed', 'start': 114.38, 'end': 115.0, 'score': 0.498}, {'word': 'in', 'start': 115.04, 'end': 115.12, 'score': 0.465}, {'word': 'the', 'start': 115.14, 'end': 115.2, 'score': 0.598}, {'word': 'wells', 'start': 115.24, 'end': 115.54, 'score': 0.356}, {'word': 'of', 'start': 117.001, 'end': 117.081, 'score': 0.64}, {'word': 'silence', 'start': 117.121, 'end': 117.601, 'score': 0.512}, {'word': 'And', 'start': 118.361, 'end': 118.602, 'score': 0.507}, {'word': 'the', 'start': 119.622, 'end': 119.822, 'score': 0.819}, {'word': 'people', 'start': 119.962, 'end': 120.482, 'score': 0.486}, {'word': 'bowed', 'start': 120.542, 'end': 120.882, 'score': 0.654}, {'word': 'and', 'start': 120.942, 'end': 121.042, 'score': 0.488}, {'word': 'prayed', 'start': 121.122, 'end': 122.643, 'score': 0.635}, {'word': 'To', 'start': 123.363, 'end': 123.803, 'score': 0.733}, {'word': 'the', 'start': 123.843, 'end': 123.964, 'score': 0.428}, {'word': 'neon', 'start': 123.984, 'end': 124.284, 'score': 0.647}, {'word': 'god', 'start': 124.324, 'end': 124.984, 'score': 0.555}, {'word': 'they', 'start': 125.024, 'end': 125.204, 'score': 0.452}, {'word': 'made', 'start': 125.224, 'end': 125.464, 'score': 0.36}, {'word': 'And', 'start': 127.245, 'end': 127.365, 'score': 0.394}, {'word': 'the', 'start': 127.425, 'end': 127.525, 'score': 0.124}, {'word': 'sign', 'start': 127.545, 'end': 127.845, 'score': 0.536}, {'word': 'flashed', 'start': 127.865, 'end': 128.105, 'score': 0.29}, {'word': 'out', 'start': 128.265, 'end': 128.525, 'score': 0.615}, {'word': 'in', 'start': 128.705, 'end': 128.845, 'score': 0.608}, {'word': 'its', 'start': 128.925, 'end': 129.045, 'score': 0.367}, {'word': 'warning', 'start': 129.105, 'end': 131.086, 'score': 0.71}, {'word': 'And', 'start': 131.146, 'end': 131.246, 'score': 0.395}, {'word': 'the', 'start': 131.306, 'end': 131.426, 'score': 0.279}, {'word': 'words', 'start': 131.466, 'end': 131.706, 'score': 0.392}, {'word': 'that', 'start': 131.746, 'end': 131.986, 'score': 0.667}, {'word': 'it', 'start': 132.046, 'end': 132.147, 'score': 0.389}, {'word': 'was', 'start': 132.187, 'end': 132.407, 'score': 0.655}, {'word': 'forming', 'start': 132.427, 'end': 133.147, 'score': 0.562}]}, {'start': 134.844, 'end': 152.817, 'text': ' In the signs and the words and the prophets are written on the subway walls and tenement halls and whispered in the sound of silence and in the naked light of', 'words': [{'word': 'In', 'start': 134.844, 'end': 135.004, 'score': 0.838}, {'word': 'the', 'start': 135.044, 'end': 135.164, 'score': 0.684}, {'word': 'signs', 'start': 135.224, 'end': 135.685, 'score': 0.654}, {'word': 'and', 'start': 135.805, 'end': 135.965, 'score': 0.438}, {'word': 'the', 'start': 136.005, 'end': 136.185, 'score': 0.416}, {'word': 'words', 'start': 136.225, 'end': 136.665, 'score': 0.467}, {'word': 'and', 'start': 136.685, 'end': 136.926, 'score': 0.541}, {'word': 'the', 'start': 136.946, 'end': 137.146, 'score': 0.288}, {'word': 'prophets', 'start': 137.186, 'end': 137.606, 'score': 0.327}, {'word': 'are', 'start': 137.746, 'end': 138.046, 'score': 0.487}, {'word': 'written', 'start': 138.106, 'end': 138.427, 'score': 0.498}, {'word': 'on', 'start': 138.627, 'end': 138.767, 'score': 0.583}, {'word': 'the', 'start': 138.827, 'end': 139.007, 'score': 0.458}, {'word': 'subway', 'start': 139.047, 'end': 139.788, 'score': 0.652}, {'word': 'walls', 'start': 140.268, 'end': 140.488, 'score': 0.484}, {'word': 'and', 'start': 141.289, 'end': 141.389, 'score': 0.651}, {'word': 'tenement', 'start': 141.449, 'end': 142.029, 'score': 0.624}, {'word': 'halls', 'start': 142.069, 'end': 142.99, 'score': 0.749}, {'word': 'and', 'start': 143.65, 'end': 143.75, 'score': 0.424}, {'word': 'whispered', 'start': 143.81, 'end': 145.392, 'score': 0.85}, {'word': 'in', 'start': 145.492, 'end': 145.552, 'score': 0.45}, {'word': 'the', 'start': 145.592, 'end': 145.692, 'score': 0.292}, {'word': 'sound', 'start': 145.732, 'end': 148.274, 'score': 0.396}, {'word': 'of', 'start': 149.394, 'end': 149.474, 'score': 0.521}, {'word': 'silence', 'start': 149.514, 'end': 150.935, 'score': 0.707}, {'word': 'and', 'start': 151.015, 'end': 151.236, 'score': 0.523}, {'word': 'in', 'start': 151.316, 'end': 151.456, 'score': 0.572}, {'word': 'the', 'start': 151.696, 'end': 151.896, 'score': 0.837}, {'word': 'naked', 'start': 151.956, 'end': 152.396, 'score': 0.655}, {'word': 'light', 'start': 152.436, 'end': 152.677, 'score': 0.418}, {'word': 'of', 'start': 152.777, 'end': 152.817, 'score': 0.038}]}, {'start': 177.968, 'end': 178.673, 'text': ' Of silence', 'words': [{'word': 'Of', 'start': 177.968, 'end': 178.049, 'score': 0.345}, {'word': 'silence', 'start': 178.129, 'end': 178.673, 'score': 0.549}]}]\n"
          ]
        }
      ],
      "source": [
        "import whisperx\n",
        "import gc\n",
        "\n",
        "device = \"cuda\"\n",
        "batch_size = 16\n",
        "compute_type = \"float16\"\n",
        "\n",
        "# Transcripción\n",
        "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "result = model.transcribe(audio, batch_size=batch_size)\n",
        "print(result[\"segments\"])\n",
        "\n",
        "# Alineación\n",
        "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
        "print(result[\"segments\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7gvheIX_TsJ0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gvheIX_TsJ0",
        "outputId": "e4f934f7-a006-496b-a5a3-6384c7586f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'start': 6.246, 'end': 7.636, 'text': \" And I'm darkness my own\", 'words': [{'word': 'And', 'start': 6.246, 'end': 6.408, 'score': 0.426}, {'word': \"I'm\", 'start': 6.448, 'end': 6.649, 'score': 0.446}, {'word': 'darkness', 'start': 6.71, 'end': 7.153, 'score': 0.626}, {'word': 'my', 'start': 7.213, 'end': 7.375, 'score': 0.76}, {'word': 'own', 'start': 7.556, 'end': 7.636, 'score': 0.206}]}, {'start': 30.336, 'end': 48.869, 'text': ' In the sound of silence In restless dreams I walked alone Narrow streets of cobblestone Neath the halo of a street lamp I turned my collar to the cold and damp', 'words': [{'word': 'In', 'start': 30.336, 'end': 30.396, 'score': 0.25}, {'word': 'the', 'start': 30.556, 'end': 30.856, 'score': 0.667}, {'word': 'sound', 'start': 30.876, 'end': 31.317, 'score': 0.424}, {'word': 'of', 'start': 32.337, 'end': 32.397, 'score': 0.659}, {'word': 'silence', 'start': 32.457, 'end': 34.279, 'score': 0.529}, {'word': 'In', 'start': 34.739, 'end': 34.839, 'score': 0.612}, {'word': 'restless', 'start': 34.879, 'end': 35.259, 'score': 0.473}, {'word': 'dreams', 'start': 35.299, 'end': 35.56, 'score': 0.638}, {'word': 'I', 'start': 35.7, 'end': 35.72, 'score': 0.009}, {'word': 'walked', 'start': 35.86, 'end': 36.54, 'score': 0.227}, {'word': 'alone', 'start': 36.7, 'end': 37.681, 'score': 0.691}, {'word': 'Narrow', 'start': 38.722, 'end': 39.082, 'score': 0.944}, {'word': 'streets', 'start': 39.102, 'end': 39.402, 'score': 0.751}, {'word': 'of', 'start': 39.462, 'end': 39.562, 'score': 0.873}, {'word': 'cobblestone', 'start': 39.622, 'end': 41.584, 'score': 0.761}, {'word': 'Neath', 'start': 42.424, 'end': 42.644, 'score': 0.479}, {'word': 'the', 'start': 42.684, 'end': 42.845, 'score': 0.635}, {'word': 'halo', 'start': 42.905, 'end': 43.405, 'score': 0.772}, {'word': 'of', 'start': 43.505, 'end': 43.565, 'score': 0.162}, {'word': 'a', 'start': 43.805, 'end': 44.266, 'score': 0.818}, {'word': 'street', 'start': 44.286, 'end': 44.586, 'score': 0.736}, {'word': 'lamp', 'start': 44.606, 'end': 45.206, 'score': 0.65}, {'word': 'I', 'start': 46.107, 'end': 46.187, 'score': 0.514}, {'word': 'turned', 'start': 46.247, 'end': 46.467, 'score': 0.435}, {'word': 'my', 'start': 46.507, 'end': 46.667, 'score': 0.631}, {'word': 'collar', 'start': 46.707, 'end': 47.148, 'score': 0.701}, {'word': 'to', 'start': 47.208, 'end': 47.448, 'score': 0.845}, {'word': 'the', 'start': 47.468, 'end': 47.568, 'score': 0.199}, {'word': 'cold', 'start': 47.648, 'end': 48.188, 'score': 0.92}, {'word': 'and', 'start': 48.268, 'end': 48.388, 'score': 0.721}, {'word': 'damp', 'start': 48.408, 'end': 48.869, 'score': 0.376}]}, {'start': 50.026, 'end': 61.5, 'text': ' When my eyes will stand by the flash of a neon light That split the night and touch the sound of silence', 'words': [{'word': 'When', 'start': 50.026, 'end': 50.186, 'score': 0.908}, {'word': 'my', 'start': 50.286, 'end': 50.527, 'score': 0.885}, {'word': 'eyes', 'start': 50.727, 'end': 50.987, 'score': 0.513}, {'word': 'will', 'start': 51.007, 'end': 51.167, 'score': 0.361}, {'word': 'stand', 'start': 51.187, 'end': 51.868, 'score': 0.749}, {'word': 'by', 'start': 51.968, 'end': 52.309, 'score': 0.74}, {'word': 'the', 'start': 52.329, 'end': 52.389, 'score': 0.042}, {'word': 'flash', 'start': 52.429, 'end': 52.869, 'score': 0.663}, {'word': 'of', 'start': 53.01, 'end': 53.19, 'score': 0.565}, {'word': 'a', 'start': 53.25, 'end': 53.27, 'score': 0.035}, {'word': 'neon', 'start': 53.31, 'end': 54.031, 'score': 0.905}, {'word': 'light', 'start': 54.171, 'end': 54.772, 'score': 0.515}, {'word': 'That', 'start': 55.633, 'end': 55.753, 'score': 0.527}, {'word': 'split', 'start': 55.773, 'end': 56.594, 'score': 0.697}, {'word': 'the', 'start': 56.614, 'end': 56.794, 'score': 0.734}, {'word': 'night', 'start': 56.854, 'end': 57.815, 'score': 0.634}, {'word': 'and', 'start': 58.436, 'end': 58.536, 'score': 0.764}, {'word': 'touch', 'start': 58.576, 'end': 58.836, 'score': 0.875}, {'word': 'the', 'start': 58.856, 'end': 58.957, 'score': 0.968}, {'word': 'sound', 'start': 59.037, 'end': 59.858, 'score': 0.703}, {'word': 'of', 'start': 60.839, 'end': 60.899, 'score': 0.626}, {'word': 'silence', 'start': 60.959, 'end': 61.5, 'score': 0.555}]}, {'start': 89.392, 'end': 91.481, 'text': \" I'm silent.\", 'words': [{'word': \"I'm\", 'start': 89.392, 'end': 89.533, 'score': 0.298}, {'word': 'silent.', 'start': 89.553, 'end': 91.481, 'score': 0.76}]}, {'start': 91.923, 'end': 92.807, 'text': 'Fool said, are you?', 'words': [{'word': 'Fool', 'start': 91.923, 'end': 92.144, 'score': 0.774}, {'word': 'said,', 'start': 92.164, 'end': 92.345, 'score': 0.382}, {'word': 'are', 'start': 92.405, 'end': 92.485, 'score': 0.203}, {'word': 'you?', 'start': 92.686, 'end': 92.807, 'score': 0.346}]}, {'start': 114.38, 'end': 133.147, 'text': ' Echoed in the wells of silence And the people bowed and prayed To the neon god they made And the sign flashed out in its warning And the words that it was forming', 'words': [{'word': 'Echoed', 'start': 114.38, 'end': 115.0, 'score': 0.498}, {'word': 'in', 'start': 115.04, 'end': 115.12, 'score': 0.465}, {'word': 'the', 'start': 115.14, 'end': 115.2, 'score': 0.598}, {'word': 'wells', 'start': 115.24, 'end': 115.54, 'score': 0.356}, {'word': 'of', 'start': 117.001, 'end': 117.081, 'score': 0.64}, {'word': 'silence', 'start': 117.121, 'end': 117.601, 'score': 0.512}, {'word': 'And', 'start': 118.361, 'end': 118.602, 'score': 0.507}, {'word': 'the', 'start': 119.622, 'end': 119.822, 'score': 0.819}, {'word': 'people', 'start': 119.962, 'end': 120.482, 'score': 0.486}, {'word': 'bowed', 'start': 120.542, 'end': 120.882, 'score': 0.654}, {'word': 'and', 'start': 120.942, 'end': 121.042, 'score': 0.488}, {'word': 'prayed', 'start': 121.122, 'end': 122.643, 'score': 0.635}, {'word': 'To', 'start': 123.363, 'end': 123.803, 'score': 0.733}, {'word': 'the', 'start': 123.843, 'end': 123.964, 'score': 0.428}, {'word': 'neon', 'start': 123.984, 'end': 124.284, 'score': 0.647}, {'word': 'god', 'start': 124.324, 'end': 124.984, 'score': 0.555}, {'word': 'they', 'start': 125.024, 'end': 125.204, 'score': 0.452}, {'word': 'made', 'start': 125.224, 'end': 125.464, 'score': 0.36}, {'word': 'And', 'start': 127.245, 'end': 127.365, 'score': 0.394}, {'word': 'the', 'start': 127.425, 'end': 127.525, 'score': 0.124}, {'word': 'sign', 'start': 127.545, 'end': 127.845, 'score': 0.536}, {'word': 'flashed', 'start': 127.865, 'end': 128.105, 'score': 0.29}, {'word': 'out', 'start': 128.265, 'end': 128.525, 'score': 0.615}, {'word': 'in', 'start': 128.705, 'end': 128.845, 'score': 0.608}, {'word': 'its', 'start': 128.925, 'end': 129.045, 'score': 0.367}, {'word': 'warning', 'start': 129.105, 'end': 131.086, 'score': 0.71}, {'word': 'And', 'start': 131.146, 'end': 131.246, 'score': 0.395}, {'word': 'the', 'start': 131.306, 'end': 131.426, 'score': 0.279}, {'word': 'words', 'start': 131.466, 'end': 131.706, 'score': 0.392}, {'word': 'that', 'start': 131.746, 'end': 131.986, 'score': 0.667}, {'word': 'it', 'start': 132.046, 'end': 132.147, 'score': 0.389}, {'word': 'was', 'start': 132.187, 'end': 132.407, 'score': 0.655}, {'word': 'forming', 'start': 132.427, 'end': 133.147, 'score': 0.562}]}, {'start': 134.844, 'end': 152.817, 'text': ' In the signs and the words and the prophets are written on the subway walls and tenement halls and whispered in the sound of silence and in the naked light of', 'words': [{'word': 'In', 'start': 134.844, 'end': 135.004, 'score': 0.838}, {'word': 'the', 'start': 135.044, 'end': 135.164, 'score': 0.684}, {'word': 'signs', 'start': 135.224, 'end': 135.685, 'score': 0.654}, {'word': 'and', 'start': 135.805, 'end': 135.965, 'score': 0.438}, {'word': 'the', 'start': 136.005, 'end': 136.185, 'score': 0.416}, {'word': 'words', 'start': 136.225, 'end': 136.665, 'score': 0.467}, {'word': 'and', 'start': 136.685, 'end': 136.926, 'score': 0.541}, {'word': 'the', 'start': 136.946, 'end': 137.146, 'score': 0.288}, {'word': 'prophets', 'start': 137.186, 'end': 137.606, 'score': 0.327}, {'word': 'are', 'start': 137.746, 'end': 138.046, 'score': 0.487}, {'word': 'written', 'start': 138.106, 'end': 138.427, 'score': 0.498}, {'word': 'on', 'start': 138.627, 'end': 138.767, 'score': 0.583}, {'word': 'the', 'start': 138.827, 'end': 139.007, 'score': 0.458}, {'word': 'subway', 'start': 139.047, 'end': 139.788, 'score': 0.652}, {'word': 'walls', 'start': 140.268, 'end': 140.488, 'score': 0.484}, {'word': 'and', 'start': 141.289, 'end': 141.389, 'score': 0.651}, {'word': 'tenement', 'start': 141.449, 'end': 142.029, 'score': 0.624}, {'word': 'halls', 'start': 142.069, 'end': 142.99, 'score': 0.749}, {'word': 'and', 'start': 143.65, 'end': 143.75, 'score': 0.424}, {'word': 'whispered', 'start': 143.81, 'end': 145.392, 'score': 0.85}, {'word': 'in', 'start': 145.492, 'end': 145.552, 'score': 0.45}, {'word': 'the', 'start': 145.592, 'end': 145.692, 'score': 0.292}, {'word': 'sound', 'start': 145.732, 'end': 148.274, 'score': 0.396}, {'word': 'of', 'start': 149.394, 'end': 149.474, 'score': 0.521}, {'word': 'silence', 'start': 149.514, 'end': 150.935, 'score': 0.707}, {'word': 'and', 'start': 151.015, 'end': 151.236, 'score': 0.523}, {'word': 'in', 'start': 151.316, 'end': 151.456, 'score': 0.572}, {'word': 'the', 'start': 151.696, 'end': 151.896, 'score': 0.837}, {'word': 'naked', 'start': 151.956, 'end': 152.396, 'score': 0.655}, {'word': 'light', 'start': 152.436, 'end': 152.677, 'score': 0.418}, {'word': 'of', 'start': 152.777, 'end': 152.817, 'score': 0.038}]}, {'start': 177.968, 'end': 178.673, 'text': ' Of silence', 'words': [{'word': 'Of', 'start': 177.968, 'end': 178.049, 'score': 0.345}, {'word': 'silence', 'start': 178.129, 'end': 178.673, 'score': 0.549}]}]\n"
          ]
        }
      ],
      "source": [
        "print(result['segments'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "saTYmjqaQZsV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "saTYmjqaQZsV",
        "outputId": "d61b148f-4add-4709-b012-0cf828385619"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'language'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-35354b59bccd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Alineación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisperx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_align_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"language\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisperx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_char_alignments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"segments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'language'"
          ]
        }
      ],
      "source": [
        "# Alineación\n",
        "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
        "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
        "print(result[\"segments\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h0OLgY2iwe4x",
      "metadata": {
        "id": "h0OLgY2iwe4x"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "yTOb6C1CPhWD",
      "metadata": {
        "id": "yTOb6C1CPhWD"
      },
      "source": [
        "⬇️ Si quieres **descargar la transcripción** como un archivo de texto, ejecuta la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Grou4Xt0PgLw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Grou4Xt0PgLw",
        "outputId": "46895aa7-89fb-41ca-ad01-c8fb9a92403f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8447a8b2-cd05-4821-a186-d191c296955f\", \"transcription.txt\", 1100)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Concatenating the transcribed segments\n",
        "transcription_text = \"\\n\".join([segment['text'] for segment in result[\"segments\"]])\n",
        "\n",
        "# Writing to a .txt file\n",
        "with open('transcription.txt', 'w') as file:\n",
        "    file.write(transcription_text)\n",
        "\n",
        "# Download the .txt file\n",
        "files.download('transcription.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XmUtiC0URDdS",
      "metadata": {
        "id": "XmUtiC0URDdS"
      },
      "source": [
        "⬇️ Y si quieres **en .json la transcripción al completo** junto a sus timestamps, ejecuta la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ATFDaiMRBq6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4ATFDaiMRBq6",
        "outputId": "26182a12-f328-4649-9987-3aa9d2280444"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_96518cce-7579-4f8b-8b7a-85b443f1dc4e\", \"transcription.json\", 56210)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Saving the entire result as a JSON file\n",
        "with open('transcription.json', 'w') as file:\n",
        "    json.dump(result, file, indent=4)\n",
        "\n",
        "# Download the JSON file\n",
        "files.download('transcription.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z52ES0u0aKgC",
      "metadata": {
        "id": "z52ES0u0aKgC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jPryNUI7f7Hl",
      "metadata": {
        "id": "jPryNUI7f7Hl"
      },
      "source": [
        "⬇️ Si quieres **cargar la transcripción a un Data Frame** para luego trabajarla a comodidad para el propósito que consideres, este es el código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hhqHlkqsaV78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "hhqHlkqsaV78",
        "outputId": "eaf2436f-a4dc-456e-eca9-ad7c8100e812"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.322121641776203,\n        \"min\": 0.982,\n        \"max\": 62.746,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          46.129,\n          53.193,\n          0.982\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.327666360318275,\n        \"min\": 15.532,\n        \"max\": 69.93,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          51.572,\n          59.137,\n          15.532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Les enregistrements ne sont pas envoy\\u00e9s \\u00e0 nos serviteurs et seulement vous avez acc\\u00e8s \\u00e0 ces enregistrements.\",\n          \"Apr\\u00e8s avoir termin\\u00e9 l'enregistrement, vous pouvez enregistrer seulement la partie n\\u00e9cessaire.\",\n          \" Hola, este es un resumen de la pagina online voicerecorder.com Voicerecorder es un dict\\u00e1fono online c\\u00f3modo y sencillo que funciona directamente en el navegador.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4f49222e-4f3c-45a0-b5e8-d35825ff14f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.982</td>\n",
              "      <td>15.532</td>\n",
              "      <td>Hola, este es un resumen de la pagina online ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.572</td>\n",
              "      <td>20.136</td>\n",
              "      <td>Permite grabar la voz a través del micrófono y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20.176</td>\n",
              "      <td>21.897</td>\n",
              "      <td>Dictáfono online gratuito.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.917</td>\n",
              "      <td>25.039</td>\n",
              "      <td>Nuestro dictáfono online es completamente grat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.059</td>\n",
              "      <td>27.201</td>\n",
              "      <td>No tiene pagos ocultos en absoluto.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27.241</td>\n",
              "      <td>30.543</td>\n",
              "      <td>No hay que pagar por activar licencias o por f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>31.340</td>\n",
              "      <td>40.626</td>\n",
              "      <td>Pouvez-vous changer les paramètres de votre m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41.246</td>\n",
              "      <td>42.807</td>\n",
              "      <td>Nous gardons la confidéncialité.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>42.847</td>\n",
              "      <td>46.109</td>\n",
              "      <td>Nous garantissons la sécurité de notre applica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>46.129</td>\n",
              "      <td>51.572</td>\n",
              "      <td>Les enregistrements ne sont pas envoyés à nos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>51.592</td>\n",
              "      <td>53.153</td>\n",
              "      <td>Enregistrement de récordation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>53.193</td>\n",
              "      <td>59.137</td>\n",
              "      <td>Après avoir terminé l'enregistrement, vous pou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>60.965</td>\n",
              "      <td>62.206</td>\n",
              "      <td>Détection automatique de silence.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>62.746</td>\n",
              "      <td>69.930</td>\n",
              "      <td>Le dictaphone en ligne détecte les zones de ba...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f49222e-4f3c-45a0-b5e8-d35825ff14f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f49222e-4f3c-45a0-b5e8-d35825ff14f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f49222e-4f3c-45a0-b5e8-d35825ff14f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30f7e173-6252-4aad-b6a7-d358ea4687e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30f7e173-6252-4aad-b6a7-d358ea4687e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30f7e173-6252-4aad-b6a7-d358ea4687e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     start     end                                               text\n",
              "0    0.982  15.532   Hola, este es un resumen de la pagina online ...\n",
              "1   15.572  20.136  Permite grabar la voz a través del micrófono y...\n",
              "2   20.176  21.897                         Dictáfono online gratuito.\n",
              "3   21.917  25.039  Nuestro dictáfono online es completamente grat...\n",
              "4   25.059  27.201                No tiene pagos ocultos en absoluto.\n",
              "5   27.241  30.543  No hay que pagar por activar licencias o por f...\n",
              "6   31.340  40.626   Pouvez-vous changer les paramètres de votre m...\n",
              "7   41.246  42.807                   Nous gardons la confidéncialité.\n",
              "8   42.847  46.109  Nous garantissons la sécurité de notre applica...\n",
              "9   46.129  51.572  Les enregistrements ne sont pas envoyés à nos ...\n",
              "10  51.592  53.153                     Enregistrement de récordation.\n",
              "11  53.193  59.137  Après avoir terminé l'enregistrement, vous pou...\n",
              "12  60.965  62.206                  Détection automatique de silence.\n",
              "13  62.746  69.930  Le dictaphone en ligne détecte les zones de ba..."
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(result['segments'])[['start', 'end', 'text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "msFqC0gJtkwI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msFqC0gJtkwI",
        "outputId": "582aeb79-9eba-4a9d-9c27-9b89d0de31db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087W1UsKDGjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "087W1UsKDGjJ",
        "outputId": "7adfb8c3-4391-4474-f05f-023a733c7022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mwhk9ibouHnp",
      "metadata": {
        "id": "mwhk9ibouHnp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcZEM3qMwhe2",
      "metadata": {
        "id": "KcZEM3qMwhe2"
      },
      "outputs": [],
      "source": [
        "transcripcion = '''foreign\n",
        "0:09\n",
        "thanks for being here tonight guys I\n",
        "0:11\n",
        "hope we're going to have a good ride\n",
        "0:12\n",
        "together I want to talk about generative\n",
        "0:15\n",
        "AI gender of tech as we call it\n",
        "0:18\n",
        "okay and uh so let me walk through how\n",
        "0:21\n",
        "we see it\n",
        "0:22\n",
        "so it feels to me like we are beginning\n",
        "0:24\n",
        "what we're calling the transition\n",
        "0:28\n",
        "the transition is essentially where\n",
        "0:30\n",
        "we're moving from carbon-based life to\n",
        "0:32\n",
        "silicon-based life and we're all\n",
        "0:34\n",
        "privileged to be on this planet\n",
        "0:37\n",
        "when this is happening some of you uh\n",
        "0:40\n",
        "might be old enough to have been\n",
        "0:41\n",
        "privileged to be here when the sort of\n",
        "0:43\n",
        "connecting took place\n",
        "0:45\n",
        "starting in 1994.\n",
        "0:48\n",
        "and we've now entered the transition\n",
        "0:51\n",
        "because so much of what we as people\n",
        "0:54\n",
        "think of human is going to be\n",
        "0:56\n",
        "increasingly located and enabled by our\n",
        "1:00\n",
        "software and our silicon and perhaps\n",
        "1:03\n",
        "even our DNA experiments over the next\n",
        "1:05\n",
        "40 or 50 years it's a big deal and we're\n",
        "1:07\n",
        "here to see it\n",
        "1:10\n",
        "Steve Jobs famously said that the\n",
        "1:12\n",
        "computer was a bicycle for the mind\n",
        "1:14\n",
        "well this is a mind guys\n",
        "1:17\n",
        "it's not a very smart mind yet but it\n",
        "1:19\n",
        "can certainly take a Wharton class as\n",
        "1:20\n",
        "we've seen you've seen that article\n",
        "1:23\n",
        "where the AI took the Wharton class and\n",
        "1:25\n",
        "got an A or B or something\n",
        "1:28\n",
        "so this is a mine and it's not just one\n",
        "1:30\n",
        "mind it's many Minds\n",
        "1:32\n",
        "it's not just one bicycle helping one\n",
        "1:34\n",
        "human it's many Minds helping each human\n",
        "1:36\n",
        "it's a big transition\n",
        "1:38\n",
        "all right\n",
        "1:39\n",
        "so if you can increase someone's output\n",
        "1:41\n",
        "by 30 we call that progress\n",
        "1:44\n",
        "but if you can increase somebody's\n",
        "1:46\n",
        "output by 20x\n",
        "1:48\n",
        "that's a revolution and we've now\n",
        "1:50\n",
        "entered that\n",
        "1:52\n",
        "okay\n",
        "1:53\n",
        "now the other thing that's happening is\n",
        "1:55\n",
        "that the internet as we know it the\n",
        "1:56\n",
        "topology is changing\n",
        "2:00\n",
        "in the old days\n",
        "2:02\n",
        "we had our stored data bases our\n",
        "2:05\n",
        "relational databases in the center of\n",
        "2:07\n",
        "the cloud\n",
        "2:08\n",
        "and we would just take our computers and\n",
        "2:10\n",
        "look at it now we're going to be able to\n",
        "2:12\n",
        "generate new data\n",
        "2:14\n",
        "on the edges of the cloud and then send\n",
        "2:16\n",
        "it back in if we want or keep it on the\n",
        "2:18\n",
        "edges if we want\n",
        "2:20\n",
        "and that just changes a lot of the way\n",
        "2:21\n",
        "the applications are going to work going\n",
        "2:23\n",
        "forward so what that means for you as\n",
        "2:24\n",
        "Founders is that there's now an opening\n",
        "2:28\n",
        "there's a wedge\n",
        "2:29\n",
        "that you can now jump in and start doing\n",
        "2:32\n",
        "things with different topologies that\n",
        "2:33\n",
        "were never done before\n",
        "2:35\n",
        "and you're going to be looking at 20x\n",
        "2:37\n",
        "productivity improvements to juice\n",
        "2:40\n",
        "the interests of your customers or users\n",
        "2:43\n",
        "right we haven't had something like this\n",
        "2:45\n",
        "happen since 2008.\n",
        "2:48\n",
        "when we got the smartphone\n",
        "2:50\n",
        "traditionally this happens about every\n",
        "2:52\n",
        "14 years if you go back looking at the\n",
        "2:54\n",
        "browser in 94.\n",
        "2:57\n",
        "2008 the mobile and now we've got the\n",
        "2:59\n",
        "generative AI okay\n",
        "3:01\n",
        "so this is that moment now I can tell\n",
        "3:03\n",
        "you as a Founder who started four\n",
        "3:05\n",
        "companies\n",
        "3:07\n",
        "and now I've been investing in hundreds\n",
        "3:09\n",
        "of companies over the last decade\n",
        "3:11\n",
        "last decade has been pretty damn boring\n",
        "3:14\n",
        "foreign\n",
        "3:16\n",
        "it's been the same old thing over and\n",
        "3:18\n",
        "over again once we got doordash and you\n",
        "3:21\n",
        "know a couple things in 2013 everything\n",
        "3:23\n",
        "kind of went quiet\n",
        "3:25\n",
        "from a seed perspective from a startup\n",
        "3:27\n",
        "perspective it was the same old stuff\n",
        "3:28\n",
        "and I can tell you sitting there we\n",
        "3:29\n",
        "review 8 000 companies a year\n",
        "3:32\n",
        "and most of the ideas are crap\n",
        "3:35\n",
        "like seven thousand nine hundred of them\n",
        "3:38\n",
        "because it's the same stuff over and\n",
        "3:40\n",
        "over again\n",
        "3:41\n",
        "and we've got a map of over 500\n",
        "3:44\n",
        "companies in the general of AI space and\n",
        "3:47\n",
        "most of them are all the same thing\n",
        "3:49\n",
        "again people aren't thinking inventively\n",
        "3:52\n",
        "because for the last 14 years we've all\n",
        "3:53\n",
        "been lulled we're all numb\n",
        "3:55\n",
        "we've got to start thinking bigger again\n",
        "3:57\n",
        "because we have that moment but that\n",
        "3:59\n",
        "moment's going to last for 24 months\n",
        "4:01\n",
        "typically it lasts for 24 30 months\n",
        "4:04\n",
        "that's about it\n",
        "4:05\n",
        "and it closes up\n",
        "4:07\n",
        "all right that's the moment you're in\n",
        "4:08\n",
        "right now\n",
        "4:09\n",
        "and so you should be paying attention\n",
        "4:11\n",
        "right now what's it going to affect it's\n",
        "4:13\n",
        "going to affect everything anything\n",
        "4:14\n",
        "you're interested in anything you're\n",
        "4:16\n",
        "working on is going to be impacted by\n",
        "4:18\n",
        "gender of tech and gender of AI\n",
        "4:20\n",
        "and it's not just that you're going to\n",
        "4:22\n",
        "be able to take what you're doing and\n",
        "4:24\n",
        "get some productivity gains\n",
        "4:26\n",
        "it's that the things that are being done\n",
        "4:28\n",
        "are going to change radically\n",
        "4:31\n",
        "and if you think big enough and you see\n",
        "4:33\n",
        "how this can happen you're going to be\n",
        "4:34\n",
        "able to really drive into that wedge and\n",
        "4:36\n",
        "create some great things\n",
        "4:38\n",
        "all right now's that moment\n",
        "4:40\n",
        "one thing I want to point out to you\n",
        "4:42\n",
        "that most people are missing in terms of\n",
        "4:44\n",
        "how they're thinking about this perhaps\n",
        "4:45\n",
        "because of the name generative Tech or\n",
        "4:47\n",
        "generate\n",
        "4:48\n",
        "is that in fact what's really amazing\n",
        "4:50\n",
        "about this stuff is that it reads well\n",
        "4:54\n",
        "it reads it summarizes it simplifies\n",
        "4:57\n",
        "it ranks it grades\n",
        "5:00\n",
        "it comments on things\n",
        "5:03\n",
        "and most people are just focusing on\n",
        "5:04\n",
        "what they can make as they make those\n",
        "5:05\n",
        "cool pictures of you being a troll king\n",
        "5:07\n",
        "or an Elven queen or whatever we can do\n",
        "5:10\n",
        "with this stuff that's great\n",
        "5:12\n",
        "but really what's amazing about it is\n",
        "5:14\n",
        "that it reads\n",
        "5:16\n",
        "now what I'll tell you is that what is\n",
        "5:18\n",
        "my job what do I do all day long\n",
        "5:21\n",
        "I read\n",
        "5:23\n",
        "I summarize I simplify I rank I collate\n",
        "5:28\n",
        "my job is going to change more in the\n",
        "5:30\n",
        "next 10 or 15 years than most other jobs\n",
        "5:34\n",
        "investment banking\n",
        "5:35\n",
        "lawyers these are the jobs that are\n",
        "5:38\n",
        "going to really change over the next 10\n",
        "5:39\n",
        "15 years doctors teachers people who\n",
        "5:42\n",
        "work at manufacturing facilities those\n",
        "5:44\n",
        "jobs will look pretty much the same 15\n",
        "5:45\n",
        "years from now as my prediction\n",
        "5:48\n",
        "but what all you big brains do\n",
        "5:51\n",
        "is going to change a lot\n",
        "5:53\n",
        "and everyone's complaining that all the\n",
        "5:55\n",
        "students can use that GPT Chat thing to\n",
        "5:57\n",
        "to you know write their essays like yeah\n",
        "5:59\n",
        "but the teachers can use it to grade the\n",
        "6:00\n",
        "essays and if you've asked it to grade\n",
        "6:02\n",
        "one of your essays you will see that you\n",
        "6:05\n",
        "get better comments from chat GPT than\n",
        "6:07\n",
        "you do from your professors\n",
        "6:10\n",
        "because they're working six days a week\n",
        "6:13\n",
        "they are way overworked\n",
        "6:15\n",
        "they can't give you the feedback they\n",
        "6:17\n",
        "want to give you they're doing their job\n",
        "6:18\n",
        "because they want to give you the\n",
        "6:19\n",
        "feedback\n",
        "6:20\n",
        "but they don't have time\n",
        "6:23\n",
        "but these things do it's going to\n",
        "6:24\n",
        "accelerate your learning it's going to\n",
        "6:26\n",
        "really change your job okay here's a way\n",
        "6:28\n",
        "to think about it\n",
        "6:30\n",
        "there's five layers in this generative\n",
        "6:31\n",
        "stack at the bottom is everything\n",
        "6:32\n",
        "everybody's talking about open AI right\n",
        "6:36\n",
        "then you're gonna have specific AI\n",
        "6:37\n",
        "models\n",
        "6:38\n",
        "things that just write tweets better\n",
        "6:40\n",
        "things that just do e-commerce photos\n",
        "6:43\n",
        "better\n",
        "6:44\n",
        "all right\n",
        "6:46\n",
        "but the general models might end up\n",
        "6:48\n",
        "supplanting those or you're going to end\n",
        "6:49\n",
        "up with Hyper local AI models which will\n",
        "6:52\n",
        "look just at your Nike photos in your\n",
        "6:54\n",
        "database because you work at Nike and\n",
        "6:55\n",
        "it's going to just make those photos\n",
        "6:56\n",
        "look just like Nike consistently with\n",
        "6:58\n",
        "the brand and your AI model will train\n",
        "7:00\n",
        "on your proprietary data and a closed\n",
        "7:03\n",
        "loop system\n",
        "7:05\n",
        "and whoever manages that AI for them\n",
        "7:07\n",
        "will have a pretty good more defensible\n",
        "7:08\n",
        "business because they can't just be\n",
        "7:10\n",
        "replaced because they have unique data\n",
        "7:12\n",
        "sets that's the third layer the\n",
        "7:14\n",
        "hyperlocal models\n",
        "7:15\n",
        "or if you have a magazine and you have a\n",
        "7:18\n",
        "certain style of writing you know you\n",
        "7:20\n",
        "train it on their 12 writers and how\n",
        "7:22\n",
        "they write and then the the AI will help\n",
        "7:24\n",
        "your writers right in that style right\n",
        "7:26\n",
        "from the get-go okay you're going to see\n",
        "7:28\n",
        "a lot of these hyper local models for\n",
        "7:30\n",
        "everything going forward\n",
        "7:32\n",
        "above that you've got your operating\n",
        "7:33\n",
        "system your API layer that's where the\n",
        "7:35\n",
        "network effects are\n",
        "7:36\n",
        "okay we're called nfx stands for Network\n",
        "7:39\n",
        "effects because we believe that the\n",
        "7:40\n",
        "biggest companies come from Network\n",
        "7:41\n",
        "effects\n",
        "7:43\n",
        "that layer that platform layer that's\n",
        "7:45\n",
        "where the network effects are\n",
        "7:47\n",
        "and then on top of that you're going to\n",
        "7:48\n",
        "have these applications you're going to\n",
        "7:49\n",
        "have these killer apps\n",
        "7:51\n",
        "like in 2004 there was a college photo\n",
        "7:53\n",
        "sharing killer app that became a big\n",
        "7:55\n",
        "platform\n",
        "7:56\n",
        "of course called Facebook then call Meta\n",
        "7:58\n",
        "and who knows what it's going to become\n",
        "8:00\n",
        "a good starting point\n",
        "8:01\n",
        "to find a killer app\n",
        "8:03\n",
        "and these killer apps are out there\n",
        "8:05\n",
        "trying to discover who they are like a\n",
        "8:06\n",
        "Jasper\n",
        "8:07\n",
        "and if they can get the right to install\n",
        "8:09\n",
        "in an application layer like an OS or an\n",
        "8:12\n",
        "API then that's probably a potentially a\n",
        "8:14\n",
        "good model\n",
        "8:17\n",
        "but beware\n",
        "8:19\n",
        "in the last\n",
        "8:20\n",
        "in the last big change in 2008\n",
        "8:23\n",
        "with the mobile phones who got most of\n",
        "8:26\n",
        "the billions\n",
        "8:27\n",
        "the incumbents\n",
        "8:29\n",
        "Apple\n",
        "8:31\n",
        "and Google they got the Android and they\n",
        "8:33\n",
        "got the iOS they got most of the\n",
        "8:35\n",
        "billions and there was some doordashing\n",
        "8:37\n",
        "and some ubering and whatnot to feed the\n",
        "8:39\n",
        "hungry miles of all the Venture\n",
        "8:40\n",
        "capitalists and feed the hungry mouths\n",
        "8:42\n",
        "of all the founders they left us some\n",
        "8:44\n",
        "crumbs but they got the most of it the\n",
        "8:45\n",
        "same thing's gonna happen here\n",
        "8:47\n",
        "except it's not going to be apple this\n",
        "8:49\n",
        "time it's going to be Microsoft because\n",
        "8:50\n",
        "they have the distribution\n",
        "8:52\n",
        "I mean Google and Microsoft are going to\n",
        "8:54\n",
        "get the majority of the value created by\n",
        "8:57\n",
        "this transformation\n",
        "8:58\n",
        "but there's still going to be many deck\n",
        "9:00\n",
        "of corns built still many unicorns built\n",
        "9:03\n",
        "in this wedge in sectors\n",
        "9:05\n",
        "that those guys won't want to pay\n",
        "9:07\n",
        "attention to or be too small for them\n",
        "9:09\n",
        "but for you a 40 or 60 billion dollar\n",
        "9:11\n",
        "company would be just fine\n",
        "9:15\n",
        "so obviously the consumers and the\n",
        "9:17\n",
        "workers are all going to win because\n",
        "9:18\n",
        "we're all going to be able to do much\n",
        "9:19\n",
        "more\n",
        "9:20\n",
        "everyone's going to get access to it\n",
        "9:21\n",
        "like water you can come it's like Google\n",
        "9:23\n",
        "and Microsoft are going to get most of\n",
        "9:25\n",
        "it\n",
        "9:25\n",
        "incumbents with distribution\n",
        "9:28\n",
        "already are going to implement this and\n",
        "9:30\n",
        "add this\n",
        "9:31\n",
        "right so nfx will add it Sequoia will\n",
        "9:34\n",
        "add it\n",
        "9:36\n",
        "and then startups that's the open Wedge\n",
        "9:38\n",
        "that's what's left for you guys and\n",
        "9:39\n",
        "that's what's less for us to invest in\n",
        "9:44\n",
        "again we've got this big map that you\n",
        "9:46\n",
        "should go check out\n",
        "9:48\n",
        "because it'll convince you that the\n",
        "9:49\n",
        "great idea you have\n",
        "9:51\n",
        "everybody else has it too\n",
        "9:53\n",
        "and I know you've built a prototype and\n",
        "9:54\n",
        "I know you've already sold ten thousand\n",
        "9:56\n",
        "dollars of it maybe fifty thousand\n",
        "9:57\n",
        "dollars of it\n",
        "9:58\n",
        "I've heard that story 60 times in the\n",
        "10:01\n",
        "last two months\n",
        "10:02\n",
        "the problem is everyone has the same\n",
        "10:04\n",
        "idea everyone's got fifty thousand\n",
        "10:06\n",
        "hundred thousand of Revenue per month\n",
        "10:08\n",
        "I get it\n",
        "10:11\n",
        "but the idea needs to be unique at this\n",
        "10:13\n",
        "point this map will show you that\n",
        "10:15\n",
        "there's already plenty of people doing\n",
        "10:16\n",
        "your idea\n",
        "10:17\n",
        "so you need to think harder\n",
        "10:18\n",
        "take the next step what's it look like\n",
        "10:20\n",
        "next\n",
        "10:23\n",
        "there's gonna be three phases of this\n",
        "10:24\n",
        "one is what we're seeing mostly most of\n",
        "10:27\n",
        "that map is this phase which is putting\n",
        "10:29\n",
        "a wrapper around the AI we'll see what\n",
        "10:31\n",
        "happens the second thing is that people\n",
        "10:32\n",
        "are going to be using generative AI to\n",
        "10:34\n",
        "do some business which has nothing to do\n",
        "10:35\n",
        "with AI\n",
        "10:36\n",
        "like renovate apartment buildings\n",
        "10:40\n",
        "we will give you a renovated apartment\n",
        "10:41\n",
        "building faster and cheaper than any\n",
        "10:44\n",
        "place else great I'm in\n",
        "10:46\n",
        "I didn't have to say anything about AI\n",
        "10:48\n",
        "I'm not selling the AI I'm using the AI\n",
        "10:50\n",
        "to make it faster and cheaper more\n",
        "10:52\n",
        "accurate\n",
        "10:54\n",
        "but I'm not selling the AI to you you're\n",
        "10:55\n",
        "not buying AI you're buying renovating\n",
        "10:57\n",
        "your apartment building in a Marketplace\n",
        "10:59\n",
        "okay\n",
        "11:01\n",
        "okay and then it's going to be the stuff\n",
        "11:03\n",
        "the Visionary stuff the stuff that we\n",
        "11:04\n",
        "can't imagine right when you first saw\n",
        "11:06\n",
        "the smartphone you didn't think oh man\n",
        "11:07\n",
        "that's really going to change taxi\n",
        "11:08\n",
        "industry\n",
        "11:10\n",
        "didn't occur to you right we didn't get\n",
        "11:12\n",
        "sidecar for about 18 months we didn't\n",
        "11:14\n",
        "get Lyft for another another six months\n",
        "11:16\n",
        "after that and Uber came a month after\n",
        "11:17\n",
        "that so it took about two years before\n",
        "11:19\n",
        "some of them were revolutionary stuff\n",
        "11:21\n",
        "started happening around the last\n",
        "11:22\n",
        "platform shift\n",
        "11:24\n",
        "those things are really exciting and I\n",
        "11:26\n",
        "encourage you all to push forward with\n",
        "11:28\n",
        "your thinking about how Everything\n",
        "11:29\n",
        "Changes Everything Changes\n",
        "11:31\n",
        "we are running a program inside our\n",
        "11:34\n",
        "company I encourage you to run it with\n",
        "11:35\n",
        "all of your friends what can be improved\n",
        "11:37\n",
        "and how you do your work as a student\n",
        "11:39\n",
        "and how any anybody you're talking to\n",
        "11:41\n",
        "how can AI play into it it's simple but\n",
        "11:44\n",
        "it's actually very few people are\n",
        "11:45\n",
        "actually spending the hours to do it\n",
        "11:46\n",
        "right now everyone's a little scared\n",
        "11:48\n",
        "I encourage you to get over that fear\n",
        "11:50\n",
        "and just do it okay uh here's the\n",
        "11:53\n",
        "problem when the internet first came out\n",
        "11:55\n",
        "in 94 a lot of people thought it was\n",
        "11:57\n",
        "stupid\n",
        "11:58\n",
        "Bob Metcalf very famous guy said it was\n",
        "12:00\n",
        "like CB radio and it was just a fad\n",
        "12:02\n",
        "what that did was it allowed the 4 000\n",
        "12:04\n",
        "people who believed in the internet\n",
        "12:06\n",
        "to have an open space to build companies\n",
        "12:08\n",
        "without too much competition\n",
        "12:11\n",
        "okay\n",
        "12:12\n",
        "uh when crypto came out I mean still\n",
        "12:14\n",
        "everyone's skeptical right how many\n",
        "12:15\n",
        "people have Bitcoins like 120 million\n",
        "12:17\n",
        "people out of 4 billion people on the\n",
        "12:19\n",
        "Internet it's still a lot of skepticism\n",
        "12:20\n",
        "about it\n",
        "12:21\n",
        "we can understand why but\n",
        "12:24\n",
        "there's a lot of skepticism which means\n",
        "12:26\n",
        "that if you get into it and believe in\n",
        "12:27\n",
        "it you can make hay that's not the case\n",
        "12:30\n",
        "here\n",
        "12:31\n",
        "what's happening here is a little bit\n",
        "12:32\n",
        "more like when Facebook opened up their\n",
        "12:33\n",
        "platform in 2008 hundreds of thousands\n",
        "12:36\n",
        "of people started building apps it was a\n",
        "12:38\n",
        "gold rush\n",
        "12:39\n",
        "same thing's happening here so you have\n",
        "12:41\n",
        "to move fast there's no Skeptics\n",
        "12:44\n",
        "everybody gets it\n",
        "12:46\n",
        "everybody gets it\n",
        "12:48\n",
        "so\n",
        "12:50\n",
        "in order to win in this you're going to\n",
        "12:51\n",
        "have to have speed you're going to have\n",
        "12:53\n",
        "to move fast and be aggressive\n",
        "12:56\n",
        "more so than other sectors that we've\n",
        "12:58\n",
        "seen in the last 20 years except for\n",
        "13:00\n",
        "that Facebook platform thing which was\n",
        "13:01\n",
        "just literally hour by hour day by day\n",
        "13:04\n",
        "whoever got ahead it was hourly guys I\n",
        "13:07\n",
        "can tell your stories I won't today but\n",
        "13:09\n",
        "it was literally hourly and so who would\n",
        "13:11\n",
        "get ahead and then their Network affect\n",
        "13:12\n",
        "their viral growth would experience so\n",
        "13:15\n",
        "uh that's coming that's that's happening'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jy_qjNkTCFew",
      "metadata": {
        "id": "Jy_qjNkTCFew"
      },
      "outputs": [],
      "source": [
        "transcripcion = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SzKKGKkSw8J5",
      "metadata": {
        "id": "SzKKGKkSw8J5"
      },
      "outputs": [],
      "source": [
        "instrucciones = '''Actua como un experto en hacer resumenes, necesito extraer todas las ideas fuerzas de un video, en un formato bullets,responde es español,\n",
        "\n",
        "la transcripcion del video es la siguiente:'''\n",
        "prompt= instrucciones + transcripcion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lWDFHTEyw_JF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "lWDFHTEyw_JF",
        "outputId": "09b4614d-eed5-4b0c-9e78-66a627befe4d"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3c060503797d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   messages=[\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XR7mM52A8U7b",
      "metadata": {
        "id": "XR7mM52A8U7b"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URCBHq62CY9Y",
      "metadata": {
        "id": "URCBHq62CY9Y"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JPfmDJbg92-3",
      "metadata": {
        "id": "JPfmDJbg92-3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lnkov95b8SXz",
      "metadata": {
        "id": "lnkov95b8SXz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"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\"\n",
        "\n",
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}